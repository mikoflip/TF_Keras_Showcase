{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I_OIQNw1q5e",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXXrSlCZY5W",
        "colab_type": "code",
        "outputId": "cc313397-0cc3-46b5-9221-fe5491859ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Import\n",
        "housing = fetch_california_housing()\n",
        "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target, test_size=0.3)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full, test_size=0.3)\n",
        "\n",
        "# PreProcessing\n",
        "scaler = MinMaxScaler((-1,1))\n",
        "x_train = scaler.fit_transform(x_train).astype(np.float32)\n",
        "x_valid = scaler.transform(x_valid).astype(np.float32)\n",
        "x_test = scaler.transform(x_test).astype(np.float32)\n",
        "\n",
        "y_train = np.expand_dims(y_train, axis=1)\n",
        "y_valid = np.expand_dims(y_valid, axis=1)\n",
        "y_test = np.expand_dims(y_test, axis=1)\n",
        "\n",
        "# Summary\n",
        "print(f\"Training Set: {len(x_train)} \\\n",
        "      \\nValidation Set: {len(x_valid)} \\\n",
        "      \\nTest Set: {len(x_test)}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Set: 10113       \n",
            "Validation Set: 4335       \n",
            "Test Set: 6192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snNZ76YoXhiG",
        "colab_type": "code",
        "outputId": "326258c3-dc07-44a2-9a55-8c69a5fb6fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.dtype"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzRrmb8SH9Ar",
        "colab_type": "text"
      },
      "source": [
        "# Keras in TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWXNkqlx1bJm",
        "colab_type": "code",
        "outputId": "fe777e8d-c4f9-43f6-bb10-c9803c6ee28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow version: 2.1.0\n",
            "Eager execution: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f9sg1ZSlQ79",
        "colab_type": "text"
      },
      "source": [
        "**Multi-Layer Perceptron using Keras Sequential API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30PqOTOth7uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "676e10f3-7eac-4a4a-ceb1-87d00c131787"
      },
      "source": [
        "keras_mlp = tf.keras.Sequential([tf.keras.layers.Dense(10, \"tanh\"),\n",
        "                                 tf.keras.layers.Dense(1)])\n",
        "\n",
        "keras_mlp.compile(\"SGD\", \"MSE\")\n",
        "keras_mlp.fit(x_train, y_train, batch_size=32, epochs=50,\n",
        "              validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10113 samples, validate on 4335 samples\n",
            "Epoch 1/50\n",
            "10113/10113 [==============================] - 3s 314us/sample - loss: 1.1125 - val_loss: 0.7940\n",
            "Epoch 2/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.6461 - val_loss: 0.5503\n",
            "Epoch 3/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.5774 - val_loss: 0.5317\n",
            "Epoch 4/50\n",
            "10113/10113 [==============================] - 1s 121us/sample - loss: 0.5627 - val_loss: 0.5346\n",
            "Epoch 5/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5529 - val_loss: 0.5367\n",
            "Epoch 6/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5478 - val_loss: 1.6895\n",
            "Epoch 7/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.5484 - val_loss: 0.5942\n",
            "Epoch 8/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.5391 - val_loss: 0.5150\n",
            "Epoch 9/50\n",
            "10113/10113 [==============================] - 1s 118us/sample - loss: 0.5342 - val_loss: 0.5181\n",
            "Epoch 10/50\n",
            "10113/10113 [==============================] - 1s 111us/sample - loss: 0.5330 - val_loss: 0.5005\n",
            "Epoch 11/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5285 - val_loss: 0.4986\n",
            "Epoch 12/50\n",
            "10113/10113 [==============================] - 1s 118us/sample - loss: 0.5273 - val_loss: 0.5008\n",
            "Epoch 13/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5257 - val_loss: 0.5459\n",
            "Epoch 14/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5238 - val_loss: 0.5185\n",
            "Epoch 15/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.5206 - val_loss: 0.5107\n",
            "Epoch 16/50\n",
            "10113/10113 [==============================] - 1s 118us/sample - loss: 0.5197 - val_loss: 0.5092\n",
            "Epoch 17/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5198 - val_loss: 0.4957\n",
            "Epoch 18/50\n",
            "10113/10113 [==============================] - 1s 121us/sample - loss: 0.5163 - val_loss: 0.8570\n",
            "Epoch 19/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.5174 - val_loss: 0.9684\n",
            "Epoch 20/50\n",
            "10113/10113 [==============================] - 1s 118us/sample - loss: 0.5159 - val_loss: 0.4836\n",
            "Epoch 21/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.5118 - val_loss: 0.4904\n",
            "Epoch 22/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5120 - val_loss: 0.4768\n",
            "Epoch 23/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5089 - val_loss: 0.6681\n",
            "Epoch 24/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.5099 - val_loss: 0.4813\n",
            "Epoch 25/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5077 - val_loss: 0.6390\n",
            "Epoch 26/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.5074 - val_loss: 0.4846\n",
            "Epoch 27/50\n",
            "10113/10113 [==============================] - 1s 118us/sample - loss: 0.5052 - val_loss: 0.5222\n",
            "Epoch 28/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5037 - val_loss: 0.5910\n",
            "Epoch 29/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.5035 - val_loss: 0.4681\n",
            "Epoch 30/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.5013 - val_loss: 0.9898\n",
            "Epoch 31/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.5029 - val_loss: 1.1312\n",
            "Epoch 32/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.5024 - val_loss: 0.7235\n",
            "Epoch 33/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.5004 - val_loss: 0.5363\n",
            "Epoch 34/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.4974 - val_loss: 0.4968\n",
            "Epoch 35/50\n",
            "10113/10113 [==============================] - 1s 111us/sample - loss: 0.4975 - val_loss: 0.5563\n",
            "Epoch 36/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.4958 - val_loss: 0.5476\n",
            "Epoch 37/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.4951 - val_loss: 0.4687\n",
            "Epoch 38/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.4950 - val_loss: 0.4602\n",
            "Epoch 39/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.4954 - val_loss: 0.5152\n",
            "Epoch 40/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.4933 - val_loss: 0.4785\n",
            "Epoch 41/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.4927 - val_loss: 0.5016\n",
            "Epoch 42/50\n",
            "10113/10113 [==============================] - 1s 114us/sample - loss: 0.4918 - val_loss: 2.1228\n",
            "Epoch 43/50\n",
            "10113/10113 [==============================] - 1s 112us/sample - loss: 0.4981 - val_loss: 0.4555\n",
            "Epoch 44/50\n",
            "10113/10113 [==============================] - 1s 116us/sample - loss: 0.4908 - val_loss: 0.6052\n",
            "Epoch 45/50\n",
            "10113/10113 [==============================] - 1s 117us/sample - loss: 0.4906 - val_loss: 0.5874\n",
            "Epoch 46/50\n",
            "10113/10113 [==============================] - 1s 111us/sample - loss: 0.4912 - val_loss: 0.4536\n",
            "Epoch 47/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.4881 - val_loss: 0.4716\n",
            "Epoch 48/50\n",
            "10113/10113 [==============================] - 1s 113us/sample - loss: 0.4889 - val_loss: 0.4733\n",
            "Epoch 49/50\n",
            "10113/10113 [==============================] - 1s 111us/sample - loss: 0.4883 - val_loss: 0.4581\n",
            "Epoch 50/50\n",
            "10113/10113 [==============================] - 1s 115us/sample - loss: 0.4871 - val_loss: 0.5801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35701472b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0hQPwnIiwyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b2a7577-849b-4c1d-ceb2-cb21179fdcf0"
      },
      "source": [
        "pred = keras_mlp.predict(x_test)\n",
        "print(f\"MSE: {np.mean((y_test - pred)**2)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.6043500663931235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dus5C4ZOiIRF",
        "colab_type": "text"
      },
      "source": [
        "**Using Keras Subclassing API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9gaRxh0YnQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(10, activation=\"tanh\")\n",
        "    self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    self.get_loss = tf.keras.losses.MeanSquaredError()\n",
        "    self.optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense1(x)\n",
        "    return self.dense2(x)\n",
        "\n",
        "  def fit(self, x, y, batch_size=32, epochs=1, validation_data=None):\n",
        "    for epoch in range(epochs):\n",
        "      print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "      training_loss = self.get_loss(y, self(x))\n",
        "\n",
        "      for i_batch in range(0, len(x), batch_size):\n",
        "        x_batch = x[i_batch:i_batch+batch_size]\n",
        "        y_batch = y[i_batch:i_batch+batch_size]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "          y_batch_pred = self(x_batch, training=True)\n",
        "          loss = self.get_loss(y_batch, y_batch_pred)\n",
        "        \n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "      x_valid, y_valid = validation_data\n",
        "      validation_loss = self.get_loss(y_valid, self(x_valid))\n",
        "      print(f\"loss: {training_loss:.4f} - val_loss: {validation_loss:.4f}\")\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self(x).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c7455e5b-60e0-482c-eb7c-8bd373e8acc9",
        "id": "pw6_g97vfIk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mlp = MLP()\n",
        "mlp.fit(x_train, y_train, batch_size=32, epochs=50,\n",
        "        validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "loss: 2.9277 - val_loss: 0.7578\n",
            "Epoch 2/50\n",
            "loss: 0.7980 - val_loss: 0.6760\n",
            "Epoch 3/50\n",
            "loss: 0.7157 - val_loss: 0.6394\n",
            "Epoch 4/50\n",
            "loss: 0.6782 - val_loss: 0.6111\n",
            "Epoch 5/50\n",
            "loss: 0.6491 - val_loss: 0.5908\n",
            "Epoch 6/50\n",
            "loss: 0.6283 - val_loss: 0.5758\n",
            "Epoch 7/50\n",
            "loss: 0.6131 - val_loss: 0.5645\n",
            "Epoch 8/50\n",
            "loss: 0.6016 - val_loss: 0.5556\n",
            "Epoch 9/50\n",
            "loss: 0.5927 - val_loss: 0.5484\n",
            "Epoch 10/50\n",
            "loss: 0.5856 - val_loss: 0.5425\n",
            "Epoch 11/50\n",
            "loss: 0.5798 - val_loss: 0.5375\n",
            "Epoch 12/50\n",
            "loss: 0.5749 - val_loss: 0.5333\n",
            "Epoch 13/50\n",
            "loss: 0.5707 - val_loss: 0.5296\n",
            "Epoch 14/50\n",
            "loss: 0.5671 - val_loss: 0.5263\n",
            "Epoch 15/50\n",
            "loss: 0.5639 - val_loss: 0.5233\n",
            "Epoch 16/50\n",
            "loss: 0.5610 - val_loss: 0.5207\n",
            "Epoch 17/50\n",
            "loss: 0.5583 - val_loss: 0.5182\n",
            "Epoch 18/50\n",
            "loss: 0.5559 - val_loss: 0.5160\n",
            "Epoch 19/50\n",
            "loss: 0.5536 - val_loss: 0.5139\n",
            "Epoch 20/50\n",
            "loss: 0.5516 - val_loss: 0.5120\n",
            "Epoch 21/50\n",
            "loss: 0.5496 - val_loss: 0.5102\n",
            "Epoch 22/50\n",
            "loss: 0.5478 - val_loss: 0.5085\n",
            "Epoch 23/50\n",
            "loss: 0.5460 - val_loss: 0.5069\n",
            "Epoch 24/50\n",
            "loss: 0.5444 - val_loss: 0.5054\n",
            "Epoch 25/50\n",
            "loss: 0.5429 - val_loss: 0.5040\n",
            "Epoch 26/50\n",
            "loss: 0.5414 - val_loss: 0.5027\n",
            "Epoch 27/50\n",
            "loss: 0.5401 - val_loss: 0.5014\n",
            "Epoch 28/50\n",
            "loss: 0.5388 - val_loss: 0.5002\n",
            "Epoch 29/50\n",
            "loss: 0.5376 - val_loss: 0.4991\n",
            "Epoch 30/50\n",
            "loss: 0.5364 - val_loss: 0.4980\n",
            "Epoch 31/50\n",
            "loss: 0.5353 - val_loss: 0.4970\n",
            "Epoch 32/50\n",
            "loss: 0.5343 - val_loss: 0.4961\n",
            "Epoch 33/50\n",
            "loss: 0.5333 - val_loss: 0.4952\n",
            "Epoch 34/50\n",
            "loss: 0.5323 - val_loss: 0.4943\n",
            "Epoch 35/50\n",
            "loss: 0.5315 - val_loss: 0.4935\n",
            "Epoch 36/50\n",
            "loss: 0.5306 - val_loss: 0.4927\n",
            "Epoch 37/50\n",
            "loss: 0.5298 - val_loss: 0.4920\n",
            "Epoch 38/50\n",
            "loss: 0.5290 - val_loss: 0.4913\n",
            "Epoch 39/50\n",
            "loss: 0.5283 - val_loss: 0.4906\n",
            "Epoch 40/50\n",
            "loss: 0.5276 - val_loss: 0.4900\n",
            "Epoch 41/50\n",
            "loss: 0.5270 - val_loss: 0.4894\n",
            "Epoch 42/50\n",
            "loss: 0.5263 - val_loss: 0.4888\n",
            "Epoch 43/50\n",
            "loss: 0.5257 - val_loss: 0.4883\n",
            "Epoch 44/50\n",
            "loss: 0.5252 - val_loss: 0.4877\n",
            "Epoch 45/50\n",
            "loss: 0.5246 - val_loss: 0.4872\n",
            "Epoch 46/50\n",
            "loss: 0.5241 - val_loss: 0.4867\n",
            "Epoch 47/50\n",
            "loss: 0.5236 - val_loss: 0.4863\n",
            "Epoch 48/50\n",
            "loss: 0.5231 - val_loss: 0.4858\n",
            "Epoch 49/50\n",
            "loss: 0.5226 - val_loss: 0.4854\n",
            "Epoch 50/50\n",
            "loss: 0.5222 - val_loss: 0.4850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0d_8kPfpNDc",
        "colab_type": "code",
        "outputId": "ddf4e4bb-ee21-43c9-ac27-6779726e92c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred = mlp.predict(x_test)\n",
        "print(f\"MSE: {np.mean((y_test - pred)**2)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.5274821604295353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8ywYbssK3A_",
        "colab_type": "text"
      },
      "source": [
        "## Experimenting with Tensors - Calculating the Jacobian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYc8A2d8MKo",
        "colab_type": "code",
        "outputId": "80017a0e-026a-4743-eebf-3c65ae0ac38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Basic gradient calculation: passing loss to GradientTape\n",
        "\n",
        "l = 5\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  pred = mlp(x_train[:l])\n",
        "  true = y_train[:l]\n",
        "  loss = mlp.get_loss(true, pred)\n",
        "\n",
        "tape.gradient(loss, mlp.trainable_variables) # dLoss/dW"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
              " array([[ 0.01813006,  0.01315879, -0.05390307, -0.07105918, -0.05422998,\n",
              "          0.02295678,  0.0037895 , -0.02438062, -0.00324793,  0.00589163],\n",
              "        [ 0.01732049, -0.00313817, -0.014398  ,  0.02074726,  0.00193153,\n",
              "          0.00289756,  0.0172822 ,  0.00069206,  0.01752797,  0.00883744],\n",
              "        [ 0.03873325,  0.02318771, -0.11454947, -0.18653479, -0.11511849,\n",
              "          0.05541396,  0.02424902, -0.05034576,  0.0042984 ,  0.01615881],\n",
              "        [ 0.04070631,  0.02398363, -0.11995587, -0.19645564, -0.12033454,\n",
              "          0.05828572,  0.02631934, -0.05254586,  0.00522891,  0.0171713 ],\n",
              "        [ 0.04356614,  0.02382907, -0.12586296, -0.21002516, -0.12510887,\n",
              "          0.06221614,  0.0317113 , -0.05432252,  0.00880596,  0.01919838],\n",
              "        [ 0.04269958,  0.02497934, -0.1256443 , -0.20614247, -0.12589677,\n",
              "          0.06113686,  0.02798224, -0.05491682,  0.00581591,  0.01809839],\n",
              "        [-0.03252755, -0.00396332,  0.07560576,  0.1622971 ,  0.06751595,\n",
              "         -0.04710811, -0.05151226,  0.02707259, -0.03111643, -0.02091006],\n",
              "        [ 0.05613823,  0.01700113, -0.14122996, -0.26358825, -0.13227843,\n",
              "          0.07844331,  0.06591811, -0.055776  ,  0.03456565,  0.03071838]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([-0.04275208, -0.02505459,  0.12586015,  0.20639458,  0.12613901,\n",
              "        -0.06121424, -0.02792997,  0.05502928, -0.00574521, -0.0181005 ],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 0.09625714],\n",
              "        [-0.15685166],\n",
              "        [ 0.04955368],\n",
              "        [-0.06867032],\n",
              "        [ 0.00056946],\n",
              "        [-0.0891624 ],\n",
              "        [-0.15700088],\n",
              "        [-0.12571238],\n",
              "        [-0.16878061],\n",
              "        [-0.15072827]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.17077442], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZpNhYS5PdnC",
        "colab_type": "code",
        "outputId": "be54573c-e87d-4795-e43b-0acaef582a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Do we get the Jacobian Matrix if we pass the vector of residuals to the GradientTape?\n",
        "\n",
        "l = 5\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  pred = mlp(x_train[:l])\n",
        "  true = y_train[:l]\n",
        "  residuals = true - pred\n",
        "\n",
        "tape.gradient(residuals, mlp.trainable_variables) # No, this is the sum of the gradients w.r.t. each residual; Proven in next cell"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
              " array([[ 0.7399844 ,  0.18966728, -1.8542768 , -3.5953655 , -1.7115018 ,\n",
              "          1.0168358 ,  0.96086246, -0.7149834 ,  0.52475536,  0.4118924 ],\n",
              "        [-0.4002539 , -0.1440517 ,  1.161946  ,  3.021617  ,  1.2696704 ,\n",
              "         -0.86525655, -0.6260009 ,  0.54300934, -0.28235042, -0.2787351 ],\n",
              "        [ 1.3583237 ,  0.36420467, -3.6173606 , -7.2596197 , -3.3582501 ,\n",
              "          1.8875772 ,  1.8708192 , -1.3863604 ,  0.9915237 ,  0.7402282 ],\n",
              "        [ 1.3969249 ,  0.37599456, -3.729312  , -7.4880342 , -3.462803  ,\n",
              "          1.9417635 ,  1.9260306 , -1.4287806 ,  1.0192653 ,  0.76032305],\n",
              "        [ 1.322643  ,  0.36490512, -3.5605912 , -7.159792  , -3.3150172 ,\n",
              "          1.8483253 ,  1.820721  , -1.3670158 ,  0.95566475,  0.7174972 ],\n",
              "        [ 1.444142  ,  0.3900773 , -3.858585  , -7.7465506 , -3.5839286 ,\n",
              "          2.0092795 ,  1.9896747 , -1.478468  ,  1.0519518 ,  0.7859582 ],\n",
              "        [ 0.57238454,  0.04169988, -1.3295074 , -2.449051  , -1.0512822 ,\n",
              "          0.5651266 ,  0.90041745, -0.41365188,  0.57092476,  0.30331153],\n",
              "        [ 0.16671957,  0.15277645, -0.60431564, -1.3853898 , -0.7378315 ,\n",
              "          0.44295827,  0.10037186, -0.33010417, -0.03585386,  0.09702663]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([-1.450115  , -0.39146012,  3.8738337 ,  7.776743  ,  3.597811  ,\n",
              "        -2.0172763 , -1.9979861 ,  1.4841943 , -1.0565538 , -0.7892553 ],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 1.2472458 ],\n",
              "        [-4.7839327 ],\n",
              "        [-0.91475105],\n",
              "        [-1.3447372 ],\n",
              "        [-0.72390795],\n",
              "        [-1.9122677 ],\n",
              "        [-2.8506427 ],\n",
              "        [ 0.09412247],\n",
              "        [-4.3610287 ],\n",
              "        [-4.045537  ]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey8dDEPg96N9",
        "colab_type": "code",
        "outputId": "d296dbe6-4dcd-48c3-9947-db4d30bd7ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Hardcoded Iterative Reproduction of Previous Cell\n",
        "\n",
        "l = 5\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  pred = mlp(x_train[:l])\n",
        "  true = y_train[:l]\n",
        "\n",
        "  r_0 = (true - pred)[0]\n",
        "  r_1 = (true - pred)[1]\n",
        "  r_2 = (true - pred)[2]\n",
        "  r_3 = (true - pred)[3]\n",
        "  r_4 = (true - pred)[4]\n",
        "\n",
        "j_0 = tape.gradient(r_0, mlp.trainable_variables)\n",
        "j_1 = tape.gradient(r_1, mlp.trainable_variables)\n",
        "j_2 = tape.gradient(r_2, mlp.trainable_variables)\n",
        "j_3 = tape.gradient(r_3, mlp.trainable_variables)\n",
        "j_4 = tape.gradient(r_4, mlp.trainable_variables)\n",
        "\n",
        "cumul = j_0\n",
        "for i in range(4):\n",
        "  cumul[i] = tf.add(cumul[i], j_1[i])\n",
        "for i in range(4):\n",
        "  cumul[i] = tf.add(cumul[i], j_2[i])\n",
        "for i in range(4):\n",
        "  cumul[i] = tf.add(cumul[i], j_3[i])\n",
        "for i in range(4):\n",
        "  cumul[i] = tf.add(cumul[i], j_4[i])\n",
        "\n",
        "cumul # Derivative with respect to each element in residuals is summed!"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
              " array([[ 0.7399844 ,  0.18966728, -1.8542768 , -3.5953655 , -1.7115017 ,\n",
              "          1.0168358 ,  0.96086246, -0.7149834 ,  0.52475536,  0.4118924 ],\n",
              "        [-0.4002539 , -0.1440517 ,  1.161946  ,  3.021617  ,  1.2696704 ,\n",
              "         -0.86525667, -0.6260009 ,  0.5430093 , -0.28235042, -0.2787351 ],\n",
              "        [ 1.3583237 ,  0.36420467, -3.6173606 , -7.2596197 , -3.3582501 ,\n",
              "          1.8875773 ,  1.8708192 , -1.3863604 ,  0.99152374,  0.7402282 ],\n",
              "        [ 1.3969249 ,  0.37599456, -3.729312  , -7.4880342 , -3.462803  ,\n",
              "          1.9417635 ,  1.9260306 , -1.4287806 ,  1.0192654 ,  0.76032317],\n",
              "        [ 1.322643  ,  0.36490512, -3.5605912 , -7.159792  , -3.3150175 ,\n",
              "          1.8483251 ,  1.820721  , -1.3670157 ,  0.9556648 ,  0.71749717],\n",
              "        [ 1.444142  ,  0.3900773 , -3.858585  , -7.7465506 , -3.5839286 ,\n",
              "          2.0092795 ,  1.9896748 , -1.478468  ,  1.0519518 ,  0.7859582 ],\n",
              "        [ 0.57238454,  0.04169988, -1.3295074 , -2.449051  , -1.051282  ,\n",
              "          0.56512666,  0.90041745, -0.4136519 ,  0.5709248 ,  0.30331153],\n",
              "        [ 0.16671959,  0.15277645, -0.60431564, -1.3853898 , -0.7378315 ,\n",
              "          0.44295827,  0.10037187, -0.33010417, -0.03585385,  0.09702663]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([-1.450115  , -0.39146012,  3.8738337 ,  7.7767434 ,  3.5978107 ,\n",
              "        -2.0172763 , -1.9979861 ,  1.4841943 , -1.0565538 , -0.7892553 ],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 1.2472458 ],\n",
              "        [-4.783932  ],\n",
              "        [-0.91475105],\n",
              "        [-1.3447372 ],\n",
              "        [-0.72390795],\n",
              "        [-1.9122677 ],\n",
              "        [-2.8506427 ],\n",
              "        [ 0.09412246],\n",
              "        [-4.3610287 ],\n",
              "        [-4.0455365 ]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A8au94uR2rR",
        "colab_type": "code",
        "outputId": "f03b43d5-2b97-402a-d035-373139a548f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Is this the way to do it?\n",
        "\n",
        "l = 5\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  pred = mlp(x_train[:l])\n",
        "  true = y_train[:l]\n",
        "  residuals = true - pred\n",
        "\n",
        "tape.jacobian(residuals, mlp.trainable_variables) # Yes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(5, 1, 8, 10), dtype=float32, numpy=\n",
              " array([[[[ 0.27391604,  0.02496682, -0.5824292 , -1.1448259 ,\n",
              "           -0.49469948,  0.3496558 ,  0.40663522, -0.20211115,\n",
              "            0.25831714,  0.16928168],\n",
              "          [-0.24626158, -0.02244618,  0.5236274 ,  1.0292449 ,\n",
              "            0.44475484, -0.31435472, -0.36558154,  0.18170612,\n",
              "           -0.23223756, -0.15219107],\n",
              "          [ 0.3488161 ,  0.03179379, -0.7416896 , -1.457869  ,\n",
              "           -0.62997097,  0.4452663 ,  0.51782626, -0.2573768 ,\n",
              "            0.32895184,  0.21557035],\n",
              "          [ 0.35050938,  0.03194813, -0.74529004, -1.4649462 ,\n",
              "           -0.63302904,  0.44742778,  0.52033997, -0.25862616,\n",
              "            0.33054867,  0.2166168 ],\n",
              "          [ 0.3011263 ,  0.02744698, -0.64028656, -1.2585508 ,\n",
              "           -0.54384196,  0.38438994,  0.4470296 , -0.22218849,\n",
              "            0.28397787,  0.18609779],\n",
              "          [ 0.35991696,  0.03280561, -0.7652934 , -1.5042648 ,\n",
              "           -0.6500194 ,  0.45943663,  0.53430575, -0.26556763,\n",
              "            0.3394205 ,  0.22243074],\n",
              "          [ 0.3429066 ,  0.03125516, -0.7291242 , -1.4331704 ,\n",
              "           -0.6192982 ,  0.43772277,  0.50905347, -0.2530164 ,\n",
              "            0.32337886,  0.21191825],\n",
              "          [-0.15416801, -0.01405206,  0.32780832,  0.64434177,\n",
              "            0.27843145, -0.1967966 , -0.2288663 ,  0.11375412,\n",
              "           -0.1453885 , -0.09527672]]],\n",
              " \n",
              " \n",
              "        [[[ 0.09418288,  0.04901391, -0.33862156, -0.7440265 ,\n",
              "           -0.34208837,  0.18940438,  0.13404988, -0.13126269,\n",
              "            0.05082428,  0.05570154],\n",
              "          [-0.14097245, -0.07336377,  0.50684696,  1.113655  ,\n",
              "            0.51203614, -0.2834995 , -0.20064518,  0.19647333,\n",
              "           -0.07607351, -0.08337379],\n",
              "          [ 0.20065665,  0.10442416, -0.72143334, -1.5851487 ,\n",
              "           -0.7288194 ,  0.4035261 ,  0.28559333, -0.27965522,\n",
              "            0.10828114,  0.11867215],\n",
              "          [ 0.20914441,  0.10884129, -0.75194985, -1.6522002 ,\n",
              "           -0.7596484 ,  0.4205952 ,  0.29767388, -0.2914846 ,\n",
              "            0.11286142,  0.12369198],\n",
              "          [ 0.21140411,  0.11001726, -0.7600743 , -1.6700515 ,\n",
              "           -0.767856  ,  0.42513952,  0.3008901 , -0.29463395,\n",
              "            0.11408083,  0.1250284 ],\n",
              "          [ 0.21966293,  0.11431526, -0.78976774, -1.7352946 ,\n",
              "           -0.79785347,  0.44174823,  0.31264484, -0.30614427,\n",
              "            0.11853757,  0.12991282],\n",
              "          [-0.06156309, -0.03203818,  0.2213416 ,  0.48633647,\n",
              "            0.2236077 , -0.12380508, -0.08762234,  0.08580049,\n",
              "           -0.03322153, -0.03640958],\n",
              "          [ 0.14596169,  0.07596023, -0.5247851 , -1.153069  ,\n",
              "           -0.53015786,  0.293533  ,  0.20774633, -0.20342682,\n",
              "            0.07876588,  0.08632451]]],\n",
              " \n",
              " \n",
              "        [[[ 0.0600282 ,  0.00893167, -0.17554057, -0.34317356,\n",
              "           -0.14423907,  0.05705467,  0.10465346, -0.05462198,\n",
              "            0.05993966,  0.0271101 ],\n",
              "          [ 0.11211145,  0.0166812 , -0.32784772, -0.6409269 ,\n",
              "           -0.2693876 ,  0.10655796,  0.19545567, -0.10201455,\n",
              "            0.11194611,  0.05063208],\n",
              "          [ 0.28719708,  0.0427324 , -0.83985096, -1.6418692 ,\n",
              "           -0.69009304,  0.27297065,  0.50070083, -0.26133174,\n",
              "            0.28677353,  0.12970473],\n",
              "          [ 0.30144495,  0.04485235, -0.88151604, -1.7233225 ,\n",
              "           -0.72432864,  0.28651273,  0.52554065, -0.27429643,\n",
              "            0.3010004 ,  0.1361394 ],\n",
              "          [ 0.29248005,  0.04351845, -0.85529995, -1.6720712 ,\n",
              "           -0.7027873 ,  0.27799192,  0.5099112 , -0.2661389 ,\n",
              "            0.2920487 ,  0.13209063],\n",
              "          [ 0.3102473 ,  0.04616207, -0.90725684, -1.7736444 ,\n",
              "           -0.74547946,  0.29487908,  0.54088676, -0.28230605,\n",
              "            0.30978975,  0.14011474],\n",
              "          [ 0.27832603,  0.04141246, -0.81390935, -1.5911546 ,\n",
              "           -0.6687772 ,  0.26453903,  0.48523504, -0.25325966,\n",
              "            0.27791557,  0.12569836],\n",
              "          [-0.12694457, -0.01888824,  0.37122428,  0.725726  ,\n",
              "            0.30502948, -0.12065632, -0.22131582,  0.11551179,\n",
              "           -0.12675735, -0.05733106]]],\n",
              " \n",
              " \n",
              "        [[[ 0.22613412,  0.06952772, -0.49399176, -0.64149517,\n",
              "           -0.42648867,  0.23186329,  0.18289022, -0.18869945,\n",
              "            0.10448851,  0.10528056],\n",
              "          [ 0.08344725,  0.02565688, -0.18229116, -0.23672238,\n",
              "           -0.1573814 ,  0.08556141,  0.06748953, -0.06963324,\n",
              "            0.038558  ,  0.03885027],\n",
              "          [ 0.3255689 ,  0.10010016, -0.7112078 , -0.9235709 ,\n",
              "           -0.61402255,  0.33381727,  0.26330996, -0.27167362,\n",
              "            0.15043376,  0.15157409],\n",
              "          [ 0.3338978 ,  0.10266098, -0.72940236, -0.9471982 ,\n",
              "           -0.6297309 ,  0.34235722,  0.27004611, -0.27862376,\n",
              "            0.15428226,  0.15545176],\n",
              "          [ 0.32230103,  0.09909541, -0.7040691 , -0.91430056,\n",
              "           -0.6078594 ,  0.33046663,  0.260667  , -0.2689467 ,\n",
              "            0.1489238 ,  0.15005268],\n",
              "          [ 0.34641686,  0.10651012, -0.75675035, -0.98271215,\n",
              "           -0.6533418 ,  0.35519344,  0.28017116, -0.28907037,\n",
              "            0.16006687,  0.16128021],\n",
              "          [ 0.03510224,  0.01079261, -0.07668111, -0.0995777 ,\n",
              "           -0.06620277,  0.03599156,  0.02838959, -0.02929135,\n",
              "            0.01621949,  0.01634244],\n",
              "          [ 0.16826294,  0.05173451, -0.3675717 , -0.47732675,\n",
              "           -0.3173437 ,  0.17252593,  0.13608581, -0.14040838,\n",
              "            0.0777483 ,  0.07833765]]],\n",
              " \n",
              " \n",
              "        [[[ 0.08572316,  0.03722716, -0.26369384, -0.72184443,\n",
              "           -0.3039862 ,  0.18885766,  0.13263361, -0.1382881 ,\n",
              "            0.05118579,  0.05451855],\n",
              "          [-0.20857854, -0.09057981,  0.64161044,  1.7563661 ,\n",
              "            0.7396484 , -0.45952174, -0.32271937,  0.33647767,\n",
              "           -0.12454344, -0.1326526 ],\n",
              "          [ 0.19608493,  0.08515418, -0.60317874, -1.6511619 ,\n",
              "           -0.6953443 ,  0.43199694,  0.30338886, -0.31632307,\n",
              "            0.11708344,  0.12470686],\n",
              "          [ 0.20192835,  0.08769181, -0.6211537 , -1.7003672 ,\n",
              "           -0.7160659 ,  0.44487062,  0.31242996, -0.3257496 ,\n",
              "            0.12057257,  0.12842318],\n",
              "          [ 0.19533156,  0.08482701, -0.60086125, -1.644818  ,\n",
              "           -0.6926727 ,  0.43033716,  0.3022232 , -0.3151077 ,\n",
              "            0.11663359,  0.12422772],\n",
              "          [ 0.20789787,  0.09028421, -0.63951665, -1.7506344 ,\n",
              "           -0.73723465,  0.45802215,  0.3216662 , -0.33537963,\n",
              "            0.12413701,  0.1322197 ],\n",
              "          [-0.02238728, -0.00972217,  0.06886573,  0.18851538,\n",
              "            0.0793884 , -0.04932167, -0.03463832,  0.03611503,\n",
              "           -0.01336757, -0.01423795],\n",
              "          [ 0.13360754,  0.058022  , -0.41099143, -1.1250619 ,\n",
              "           -0.47379082,  0.29435226,  0.20672184, -0.21553488,\n",
              "            0.07977782,  0.08497224]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 1, 10), dtype=float32, numpy=\n",
              " array([[[-0.3621494 , -0.03300909,  0.7700403 ,  1.5135953 ,\n",
              "           0.65405124, -0.46228635, -0.5376199 ,  0.26721486,\n",
              "          -0.34152582, -0.2238104 ]],\n",
              " \n",
              "        [[-0.22026946, -0.1146309 ,  0.79194844,  1.740086  ,\n",
              "           0.80005646, -0.44296798, -0.3135081 ,  0.30698958,\n",
              "          -0.11886487, -0.13027154]],\n",
              " \n",
              "        [[-0.31142068, -0.04633665,  0.9106881 ,  1.7803525 ,\n",
              "           0.7482989 , -0.2959943 , -0.5429324 ,  0.28337374,\n",
              "          -0.3109614 , -0.14064465]],\n",
              " \n",
              "        [[-0.34769687, -0.10690367,  0.7595465 ,  0.98634326,\n",
              "           0.6557559 , -0.35650587, -0.28120637,  0.29013848,\n",
              "          -0.16065831, -0.16187614]],\n",
              " \n",
              "        [[-0.20857854, -0.09057981,  0.64161044,  1.7563661 ,\n",
              "           0.7396484 , -0.45952174, -0.32271937,  0.33647767,\n",
              "          -0.12454344, -0.1326526 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 1, 10, 1), dtype=float32, numpy=\n",
              " array([[[[ 0.11689157],\n",
              "          [-0.98208475],\n",
              "          [-0.39358106],\n",
              "          [-0.43237662],\n",
              "          [-0.45001858],\n",
              "          [-0.22677535],\n",
              "          [-0.36410475],\n",
              "          [ 0.4598973 ],\n",
              "          [-0.7870687 ],\n",
              "          [-0.71671486]]],\n",
              " \n",
              " \n",
              "        [[[ 0.63252074],\n",
              "          [-0.936315  ],\n",
              "          [-0.36174935],\n",
              "          [-0.25551265],\n",
              "          [ 0.15650205],\n",
              "          [-0.30177274],\n",
              "          [-0.7029705 ],\n",
              "          [-0.30682048],\n",
              "          [-0.9314304 ],\n",
              "          [-0.8467182 ]]],\n",
              " \n",
              " \n",
              "        [[[-0.3896491 ],\n",
              "          [-0.9747581 ],\n",
              "          [-0.02344565],\n",
              "          [-0.20894246],\n",
              "          [-0.29597437],\n",
              "          [-0.62661344],\n",
              "          [-0.35213748],\n",
              "          [ 0.40475193],\n",
              "          [-0.808413  ],\n",
              "          [-0.8333018 ]]],\n",
              " \n",
              " \n",
              "        [[[ 0.23027378],\n",
              "          [-0.9407435 ],\n",
              "          [ 0.4079493 ],\n",
              "          [-0.6856901 ],\n",
              "          [-0.44770333],\n",
              "          [-0.5181503 ],\n",
              "          [-0.73911095],\n",
              "          [-0.37929255],\n",
              "          [-0.9060888 ],\n",
              "          [-0.80514455]]],\n",
              " \n",
              " \n",
              "        [[[ 0.6572088 ],\n",
              "          [-0.9500309 ],\n",
              "          [-0.5439242 ],\n",
              "          [ 0.2377847 ],\n",
              "          [ 0.31328627],\n",
              "          [-0.23895572],\n",
              "          [-0.6923189 ],\n",
              "          [-0.08441377],\n",
              "          [-0.9280278 ],\n",
              "          [-0.84365743]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 1, 1), dtype=float32, numpy=\n",
              " array([[[-1.]],\n",
              " \n",
              "        [[-1.]],\n",
              " \n",
              "        [[-1.]],\n",
              " \n",
              "        [[-1.]],\n",
              " \n",
              "        [[-1.]]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}